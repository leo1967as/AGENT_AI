import json
import os
import uuid
from datetime import datetime

import requests
from bs4 import BeautifulSoup
from fastmcp import FastMCP

# --- üí° 1. ‡πÄ‡∏û‡∏¥‡πà‡∏° import ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏´‡∏°‡πà ---
import chromadb
import pypdf
import docx
from duckduckgo_search import DDGS
import numexpr as ne
import pandas as pd
import yfinance as yf
from dotenv import load_dotenv

# ‡∏™‡∏£‡πâ‡∏≤‡∏á MCP instance
mcp = FastMCP("The Archivist's Tools")

# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢
WORKSPACE_DIR = "workspace"
os.makedirs(WORKSPACE_DIR, exist_ok=True)

# --- Memory Setup ---
MEMORY_DIR = "memory_db"
os.makedirs(MEMORY_DIR, exist_ok=True)
client = chromadb.PersistentClient(path=MEMORY_DIR)
memory_collection = client.get_or_create_collection(name="memories")

# --- NEW MEMORY TOOLS ---

@mcp.tool()
def save_memory_chunk(content: str, metadata: dict = None) -> str:
    """
    ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å "‡∏ä‡∏¥‡πâ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏£‡∏á‡∏à‡∏≥" (content) ‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏•‡∏á‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡∏£‡∏∞‡∏¢‡∏∞‡∏¢‡∏≤‡∏ß
    """
    print(f"--- Saving memory chunk: '{content[:50]}...' ---")
    try:
        doc_id = f"mem_{int(datetime.now().timestamp())}"

        # --- üí° ‡∏à‡∏∏‡∏î‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç ---
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á final_metadata ‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤
        final_metadata = metadata or {}

        # ‡πÄ‡∏û‡∏¥‡πà‡∏° timestamp ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÇ‡∏î‡∏¢‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡πÄ‡∏™‡∏°‡∏≠
        # ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤ metadata ‡∏à‡∏∞‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤
        final_metadata['saved_at'] = datetime.now().isoformat()

        memory_collection.add(
            documents=[content],
            metadatas=[final_metadata], # <--- ‡πÉ‡∏ä‡πâ final_metadata ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏°‡∏≠
            ids=[doc_id]
        )
        return json.dumps({"status": "success", "message": f"Memory chunk saved with ID {doc_id}."})
    except Exception as e:
        return json.dumps({"error": f"Failed to save memory: {str(e)}"})

@mcp.tool()
def search_relevant_memories(query: str, n_results: int = 5) -> str:
    """
    ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ memories ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏à‡∏≤‡∏Å ChromaDB ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ semantic search
    Args:
        query (str): ‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
        n_results (int): ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ (default=5)
    """
    try:
        results = memory_collection.query(query_texts=[query], n_results=n_results)
        memories = []
        if results['documents']:
            for doc, meta, id in zip(results['documents'][0], results['metadatas'][0], results['ids'][0]):
                memories.append({"id": id, "content": doc, "metadata": meta})
        return json.dumps({"memories": memories}, ensure_ascii=False)
    except Exception as e:
        return json.dumps({"error": str(e)}, ensure_ascii=False)

# ------------------- EXISTING TOOLS -------------------

@mcp.tool()
def browse_url(url: str) -> str:
    """
    ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡∏≠‡πà‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡∏î‡∏∂‡∏á "‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏´‡∏•‡∏±‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∞‡∏≠‡∏≤‡∏î" ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å URL ‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤
    ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏•‡∏ö‡πÄ‡∏°‡∏ô‡∏π, ‡πÇ‡∏Ü‡∏©‡∏ì‡∏≤, ‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏≠‡∏Å
    """
    print(f"--- Server browsing URL with Simple Method: {url} ---")
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        response = requests.get(url, timeout=15, headers=headers)
        response.raise_for_status()

        soup = BeautifulSoup(response.content, 'lxml')

        # ‡∏•‡∏ö‡πÅ‡∏ó‡πá‡∏Å‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏´‡∏•‡∏±‡∏Å‡∏≠‡∏≠‡∏Å‡πÑ‡∏õ‡πÉ‡∏´‡πâ‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
        for element in soup(["script", "style", "nav", "footer", "header", "aside", "form"]):
            element.decompose()
        
        # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏≠‡∏Å‡∏°‡∏≤ ‡πÇ‡∏î‡∏¢‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏Ç‡∏∂‡πâ‡∏ô‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢
        text = soup.get_text(separator='\n', strip=True)
        
        if not text:
            return json.dumps({"error": "Could not extract text content from the URL."}, ensure_ascii=False)

        # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ context ‡∏Ç‡∏≠‡∏á Agent ‡∏¢‡∏≤‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
        max_length = 15000
        truncated_text = text[:max_length]

        print(f"--- Extracted text length: {len(truncated_text)} characters. ---")
        # ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏™‡∏∞‡∏≠‡∏≤‡∏î ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡πÉ‡∏ô tool ‡∏ô‡∏µ‡πâ
        return json.dumps({"url": url, "content": truncated_text}, ensure_ascii=False)

    except Exception as e:
        print(f"!!! ERROR in browse_url tool: {e} !!!")
        return json.dumps({"error": f"An exception occurred while browsing the URL: {str(e)}"}, ensure_ascii=False)

@mcp.tool()
def web_search(query: str, num_results: int = 5) -> str:
    """‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ß‡πá‡∏ö‡∏î‡πâ‡∏ß‡∏¢ DuckDuckGo ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô Args: query (str), num_results (int, default=5)"""
    print(f"--- Server received web_search request for query: '{query}' ---")
    try:
        with DDGS() as ddgs:
            # --- üí° ‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏° `backend="lite"` ---
            # "lite" backend ‡∏à‡∏∞‡πÉ‡∏ä‡πâ DuckDuckGo ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏á‡πà‡∏≤‡∏¢, ‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß, ‡πÅ‡∏•‡∏∞‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
            # ‡πÅ‡∏•‡∏∞‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ñ‡∏∑‡∏≠ "‡∏à‡∏∞‡πÑ‡∏°‡πà" ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÑ‡∏õ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡πÄ‡∏≠‡∏ô‡∏à‡∏¥‡πâ‡∏ô‡∏≠‡∏∑‡πà‡∏ô ‡πÄ‡∏ä‡πà‡∏ô Brave
            results = list(ddgs.text(query, backend="lite", max_results=num_results))

        if not results:
            return json.dumps({"error": "No results found from DuckDuckGo."})

        output = [{
            "title": r.get('title', 'No Title'),
            "snippet": r.get('body', '')[:300] + "...",
            "url": r.get('href', '')
        } for r in results]

        return json.dumps(output, ensure_ascii=False, indent=2)

    except Exception as e:
        print(f"!!! ERROR in web_search tool: {e} !!!")
        return json.dumps({"error": f"An exception occurred during search: {str(e)}"})

@mcp.tool()
def get_stock_price(tickers: list[str], period: str = "10d") -> str:
    """
    ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏Ñ‡∏≤‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏Ç‡∏≠‡∏á‡∏´‡∏∏‡πâ‡∏ô‡∏à‡∏≤‡∏Å Yahoo Finance ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Ticker "‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß" ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô
    Args:
        tickers (list[str]): ‡∏•‡∏¥‡∏™‡∏ï‡πå‡∏Ç‡∏≠‡∏á‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå‡∏´‡∏∏‡πâ‡∏ô ‡πÄ‡∏ä‡πà‡∏ô ['NVDA', 'AAPL'].
        period (str): ‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á (e.g., '10d', '1mo').
    """
    try:
        # --- üí° ‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏° `timeout=15` ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ ---
        # ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ yfinance ‡∏Ñ‡πâ‡∏≤‡∏á‡∏ô‡∏≤‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏à‡∏≠ Ticker ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á
        data = yf.download(tickers, period=period, timeout=15)

        if data.empty:
            return json.dumps({"error": f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö tickers ‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏"})

        results = {}
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ tickers ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ö‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô list ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà (‡∏Å‡∏£‡∏ì‡∏µ yf.download ‡πÑ‡∏î‡πâ ticker ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß)
        ticker_list = tickers if isinstance(tickers, list) else [tickers]

        # ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏µ‡πà data ‡∏°‡∏µ column level ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß (‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏î‡πâ ticker ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß)
        if not isinstance(data.columns, pd.MultiIndex):
            data.columns.name = 'Date'
            data = data.reset_index()
            records = data[['Date', 'Open', 'High', 'Low', 'Close', 'Volume']].to_dict('records')
            results[ticker_list[0]] = records
        else: # ‡∏Å‡∏£‡∏ì‡∏µ‡πÑ‡∏î‡πâ‡∏´‡∏•‡∏≤‡∏¢ tickers
            for ticker in ticker_list:
                ticker_data = data.loc[:, (slice(None), ticker)]
                ticker_data.columns = ticker_data.columns.droplevel(1)

                if ticker_data.empty:
                    results[ticker] = {"error": "No data found for this specific ticker."}
                    continue

                df = ticker_data.reset_index()
                records = df[['Date', 'Open', 'High', 'Low', 'Close', 'Volume']].to_dict('records')
                results[ticker] = records

        return json.dumps(results, default=str, ensure_ascii=False)
    except Exception as e:
        return json.dumps({"error": str(e)}, ensure_ascii=False)

@mcp.tool()
def calculator(expression: str) -> str:
    """
    ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ô‡∏¥‡∏û‡∏à‡∏ô‡πå‡∏ó‡∏≤‡∏á‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô
    ‡∏£‡∏±‡∏ö Input ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏ï‡∏£‡∏¥‡∏á‡∏Ç‡∏≠‡∏á‡∏™‡∏°‡∏Å‡∏≤‡∏£ (‡πÄ‡∏ä‡πà‡∏ô "5 + (9 - 4) * 3650") ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    """
    print(f"--- Calculator received expression: '{expression}' ---")
    try:
        # ‡πÉ‡∏ä‡πâ numexpr.evaluate ‡∏ã‡∏∂‡πà‡∏á‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏Å‡∏ß‡πà‡∏≤ eval() ‡∏°‡∏≤‡∏Å
        result = ne.evaluate(expression).item()
        return json.dumps({"result": result}, ensure_ascii=False)
    except Exception as e:
        print(f"!!! ERROR in calculator tool: {e} !!!")
        return json.dumps({"error": f"Invalid mathematical expression: {str(e)}"})

@mcp.tool()
def get_current_date() -> str:
    """‡∏î‡∏∂‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏•‡∏∞‡πÄ‡∏ß‡∏•‡∏≤‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢"""
    try:
        now = datetime.now()
        thai_year = now.year + 543  # ‡∏õ‡∏µ‡∏û‡∏∏‡∏ó‡∏ò‡∏®‡∏±‡∏Å‡∏£‡∏≤‡∏ä
        
        # ‡πÉ‡∏ä‡πâ helper functions ‡πÅ‡∏ó‡∏ô locale ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏ö‡∏ô Windows
        thai_months = ["‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°", "‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå", "‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°", "‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô", "‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°", "‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô",
                      "‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°", "‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°", "‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô", "‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°", "‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô", "‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°"]
        thai_days = ["‡∏ß‡∏±‡∏ô‡∏à‡∏±‡∏ô‡∏ó‡∏£‡πå", "‡∏ß‡∏±‡∏ô‡∏≠‡∏±‡∏á‡∏Ñ‡∏≤‡∏£", "‡∏ß‡∏±‡∏ô‡∏û‡∏∏‡∏ò", "‡∏ß‡∏±‡∏ô‡∏û‡∏§‡∏´‡∏±‡∏™‡∏ö‡∏î‡∏µ", "‡∏ß‡∏±‡∏ô‡∏®‡∏∏‡∏Å‡∏£‡πå", "‡∏ß‡∏±‡∏ô‡πÄ‡∏™‡∏≤‡∏£‡πå", "‡∏ß‡∏±‡∏ô‡∏≠‡∏≤‡∏ó‡∏¥‡∏ï‡∏¢‡πå"]
        
        thai_month = thai_months[now.month - 1]
        thai_day_name = thai_days[now.weekday()]
        
        formatted_date = f"{thai_day_name}‡∏ó‡∏µ‡πà {now.day} {thai_month} {thai_year} ‡πÄ‡∏ß‡∏•‡∏≤ {now.hour:02d}:{now.minute:02d}:{now.second:02d}"
        
        return json.dumps({"current_datetime": formatted_date}, ensure_ascii=False)
    except Exception as e:
        return json.dumps({"error": str(e)})

# ------------------- FILE TOOLS -------------------

def _get_safe_path(filename: str) -> str | None:
    # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏≠‡∏Å workspace (e.g., "../secret.txt")
    if ".." in filename or "/" in filename or "\\" in filename:
        return None
    return os.path.join(WORKSPACE_DIR, filename)

@mcp.tool()
def write_to_file(filename: str, content: str) -> str:
    """‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô workspace ‡∏ó‡∏µ‡πà‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢. Args: filename (str), content (str)"""
    safe_path = _get_safe_path(filename)
    if not safe_path:
        return json.dumps({"error": "Invalid filename. Path traversal not allowed."})
    
    try:
        with open(safe_path, 'w', encoding='utf-8') as f:
            f.write(content)
        return json.dumps({"success": f"File '{filename}' written successfully."})
    except Exception as e:
        return json.dumps({"error": str(e)})

@mcp.tool()
def read_from_file(filename: str) -> str:
    """‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô workspace ‡∏ó‡∏µ‡πà‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢. Args: filename (str)"""
    safe_path = _get_safe_path(filename)
    if not safe_path:
        return json.dumps({"error": "Invalid filename. Path traversal not allowed."})
    
    try:
        with open(safe_path, 'r', encoding='utf-8') as f:
            content = f.read()
        return json.dumps({"content": content})
    except FileNotFoundError:
        return json.dumps({"error": f"File '{filename}' not found."})
    except Exception as e:
        return json.dumps({"error": str(e)})

# ------------------- MAIN EXECUTION BLOCK -------------------

if __name__ == "__main__":
    mcp.run(transport="stdio")